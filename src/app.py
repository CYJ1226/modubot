### [1] í•„ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬ import

# API KEY í˜¸ì¶œ
import os
from dotenv import load_dotenv

# ì›ë³¸ íŒŒì¼ ì •ë¦¬
from pathlib import Path
import pandas as pd
from langchain_community.document_loaders import PyPDFLoader, UnstructuredHTMLLoader, Docx2txtLoader
from langchain_community.document_loaders.csv_loader import CSVLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_core.documents import Document

# í…ìŠ¤íŠ¸ ì„ë² ë”© ë° VectorDB
from langchain_openai import OpenAIEmbeddings
from langchain_chroma import Chroma

# Chain êµ¬ì¶•
from langchain_openai import ChatOpenAI
from langchain_community.chat_message_histories import ChatMessageHistory
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough

# Reranker, Reorderë¥¼ í†µí•œ RAG ê³ ë„í™”
from langchain.retrievers import ContextualCompressionRetriever
from langchain_cohere import CohereRerank
from langchain_community.document_transformers import LongContextReorder
from langchain.retrievers.document_compressors import DocumentCompressorPipeline

# streamlitì„ í†µí•´ ì›¹ì‚¬ì´íŠ¸ ìƒì„±
import streamlit as st
import datetime as dt
from streamlit_lottie import st_lottie
import requests

### [2] í™˜ê²½ë³€ìˆ˜ ë¶ˆëŸ¬ì˜¤ê¸°
load_dotenv() # í˜„ì¬ ë””ë ‰í† ë¦¬ì˜ .env íŒŒì¼ì„ ì½ì–´ os í™˜ê²½ë³€ìˆ˜ì— ë„£ì–´ì¤Œ
# os í™˜ê²½ë³€ìˆ˜ë¥¼ ë¶ˆëŸ¬ì˜´
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
COHERE_API_KEY = os.getenv("COHERE_API_KEY")

### [3] ë¬¸ì„œ ë¶ˆëŸ¬ì™€ VectorDBì— ì €ì¥
# Path ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ í†µí•´ ê²½ë¡œë¥¼ ë¬¸ìì—´ì´ ì•„ë‹Œ ê°ì²´ë¡œ ë‹¤ë¤„ ì´ì‹ì„± í™•ë³´
BASE_DATA_DIR = Path("..") / "data"
PDF_DIR, HTML_DIR, WORD_DIR, CSV_DIR = [BASE_DATA_DIR / i for i in ["pdf", "html", "word", "csv"]]

# ë…ë¦½ì ì¸ í–‰(row)ìœ¼ë¡œ êµ¬ì„±ë¼ìˆë˜ ì›ë³¸ ì¶œì„ ë°ì´í„°ë¥¼ í•™ìƒë³„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ Document ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜
def create_grouped_documents(csv_path: str) -> list[Document]:
    try:
        df = pd.read_csv(csv_path, encoding='cp949')
        required_cols = ['ì´ë¦„', 'ì‚¬ìœ ', 'ë‚ ì§œ', 'ë¶€ì¬ì‹œê°„', 'ìƒíƒœ']
        df = df[required_cols].fillna('')
        
        documents = []
        for name, group_df in df.groupby('ì´ë¦„'):
            records = "\n".join([f"ì‚¬ìœ : {r['ì‚¬ìœ ']}, ë‚ ì§œ: {r['ë‚ ì§œ']}, ìƒíƒœ: {r['ìƒíƒœ']}, ë¶€ì¬ì‹œê°„: {r['ë¶€ì¬ì‹œê°„']}" 
                                    for _, r in group_df.iterrows()])
            documents.append(Document(
                page_content=f"í•™ìƒ ì´ë¦„: {name}\n\n--- ì „ì²´ ì¶œê²° ê¸°ë¡ ì‹œì‘ ---\n{records}",
                metadata={'í•™ìƒì´ë¦„': name, 'ì´ê¸°ë¡ìˆ˜': len(group_df)}
            ))
        return documents
    except Exception as e:
        st.error(f"ì¼ì •í‘œ ë¡œë”© ì‹¤íŒ¨: {e}")
        return []

# Loaderë¡œ ë¬¸ì„œ ë¶ˆëŸ¬ì™€ VectorDBì— ì €ì¥í•˜ëŠ” í•¨ìˆ˜
@st.cache_resource
def get_vectorstore():
    # Loader => íŒŒì¼ ì½ì„ ì¤€ë¹„ (íŒŒì‹± ì „ëµ)
    # load => ì‹¤ì œë¡œ ì½ì–´ Document ê°ì²´ ìƒì„±
    # RecursiveCharacterTextSplitter => ë¬¸ì„œë¥¼ ì–´ë–»ê²Œ ë¶„í• í• ê±´ì§€ ì„¤ì •
    # split_documents => metadata ìœ ì§€í•˜ë©´ì„œ Document ê°ì²´ë¥¼ ë” ì‘ì€ ë‹¨ìœ„ì˜ Document ê°ì²´ë¡œ ë¶„í• 

    embeddings = OpenAIEmbeddings(model_name="text-embedding-3-large")
    # í…ìŠ¤íŠ¸ ë¶„í• ê¸°
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=512,
        chunk_overlap=128,
        separators=["\n\n", "\n", " ", ""]
    )

    all_docs = []

    # í†µí•© Loader ì„¤ì •
    # (ë¡œë” í´ë˜ìŠ¤, íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸, ì†ŒìŠ¤ íƒ€ì… ì´ë¦„)
    file_configs = [
        (PyPDFLoader, list(PDF_DIR.glob("*.pdf")), "pdf"),
        (Docx2txtLoader, list(WORD_DIR.glob("*.docx")), "word"),
        (UnstructuredHTMLLoader, list(HTML_DIR.glob("*.html")), "html"),
        (CSVLoader, [CSV_DIR / "ë°ì‹¸ 5ê¸° ë™ë£Œë“¤.csv", CSV_DIR / "ë°ì‹¸ 5ê¸° ìš´ì˜ì§„.csv"], "csv")
    ]

    # ë°˜ë³µë¬¸ì„ í†µí•œ íš¨ìœ¨ì  ë¡œë”©
    for loader_cls, paths, s_type in file_configs:
        for path in paths:
            try:
                # CSVLoaderì˜ ê²½ìš° cp949ë¡œ encoding í•´ì•¼ ê¸€ìê°€ ì•ˆê¹¨ì§€ë¯€ë¡œ ë³„ë„ ì²˜ë¦¬
                loader = loader_cls(str(path), encoding='cp949') if loader_cls == CSVLoader else loader_cls(str(path))
                loaded_pages = loader.load()
                
                # ë©”íƒ€ë°ì´í„° ì£¼ì… ë° ë¦¬ìŠ¤íŠ¸ í†µí•©
                for d in loaded_pages:
                    d.metadata["source_type"] = s_type
                    d.metadata["source"] = path.name
                
                all_docs.extend(text_splitter.split_documents(loaded_pages))
            except Exception as e:
                print(f"ë¡œë”© ì‹¤íŒ¨ ({path}): {e}")

    # íŠ¹ìˆ˜ ë¡œì§ì´ í•„ìš”í•œ ë°ì´í„° ì²˜ë¦¬ (ì¼ì •í‘œ)
    attendance_path = CSV_DIR / "ë°ì‹¸ 5ê¸° ì¼ì •í‘œ.csv"
    if attendance_path.exists():
        # êµìœ¡ìƒ ê¸°ì¤€ìœ¼ë¡œ ê·¸ë£¹í™” í•˜ëŠ” í•¨ìˆ˜ í˜¸ì¶œ
        attendance_docs = create_grouped_documents(str(attendance_path))
        # ì´ë¦„ë³„ë¡œ ë¬¶ì—ˆëŠ”ë° í•œ ëª…ì— ëŒ€í•œ ë°ì´í„°ê°€ ë„ˆë¬´ ë§ìœ¼ë©´ ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš° ë¬¸ì œ, í† í° ë¬¸ì œ ì¡´ì¬í•˜ê³  í™•ì¥ì„±ì— ë¶ˆë¦¬
        # metadataì— ì´ë¦„ ìˆê³ , ë™ì¼ ì´ë¦„ë¼ë¦¬ ê·¼ì²˜ì— ìˆìœ¼ë¯€ë¡œ split í•´ë„ ì„±ëŠ¥ ì €í•˜ ì—†ìŒ
        all_docs.extend(text_splitter.split_documents(attendance_docs))

    # ë²¡í„° DB ì¼ê´„ ìƒì„±
    vectorstore = Chroma.from_documents(
        documents=all_docs, 
        embedding=embeddings
    )
    
    return vectorstore

### [4] Retriever ì„¤ê³„
# Retrievalê³¼ Chainì„ ì„¤ê³„í•˜ëŠ” í•¨ìˆ˜
@st.cache_resource
def get_conversational_rag_chain():
    vectorstore = get_vectorstore()
    llm = ChatOpenAI(model='gpt-4o-mini', temperature=0)

    # base_retriever => mmrì„ ì‚¬ìš©í•˜ì—¬ ì§ˆë¬¸ì— ëŒ€í•œ ì—¬ëŸ¬ ê´€ì ì˜ ì •ë³´ë¥¼ ëª¨ì•„ ìœ ì‚¬ì„±ê³¼ ë‹¤ì–‘ì„±ì„ ê³ ë ¤í•œ ë¬¸ì„œ ê²€ìƒ‰
    # Rerank => base_retriever ì—ì„œ ê³ ë¥¸ í›„ë³´ 25ê°œ ì¤‘, ì§ˆë¬¸ì— ì‹¤ì œë¡œ ë‹µí•  ìˆ˜ ìˆëŠ” ë¬¸ì„œ 10ê°œ ì¶”ì¶œ
    # Reorder => LLMì€ ì²˜ìŒê³¼ ëì€ ì˜ ê¸°ì–µí•˜ì§€ë§Œ ì¤‘ê°„ì— ìˆëŠ” ì •ë³´ëŠ” ì˜ ë†“ì¹˜ëŠ” in the middle í˜„ìƒì´ ìˆì–´ rerankerê°€ ê³¨ë¼ì¤€ top 10ë¬¸ì„œì— ëŒ€í•´ ì¤‘ìš”í•œ ì •ë³´ë“¤ì€ LLMì˜ ì‹œì„ ì´ ì§‘ì¤‘ë˜ëŠ” ì–‘ ëë‹¨ì— ë°°ì¹˜

    base_retriever = vectorstore.as_retriever(search_type="mmr",  search_kwargs={"lambda_mult": 0.5, "fetch_k": 50, "k": 25})
    compressor = DocumentCompressorPipeline(transformers=[
        CohereRerank(model="rerank-multilingual-v3.0", top_n=10),
        LongContextReorder()
    ])
    
    # base_retrieverì— reorderì™€ rerankê°€ ì¶”ê°€ëœ retriever
    upgraded_retriever = ContextualCompressionRetriever(base_retriever=base_retriever, base_compressor=compressor)

    ### [5] Chain êµ¬ì„±
    # ì§ˆë¬¸ ì¬ì‘ì„±ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸
    # ì§ˆë¬¸ì´ "ê·¸ ì‚¬ëŒì˜ MBTI"ë¼ë©´, LLMì—ê²Œ ë„˜ê¸°ê¸° ì „ì— ê·¸ ì‚¬ëŒì´ ëˆ„êµ°ì§€ ì´ì „ ëŒ€í™” ë§¥ë½ì„ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì„ ì¬ì‘ì„±í•˜ì—¬ ë„˜ê²¨ì¤Œ
    rephrase_system_prompt = """
        ë‹¹ì‹ ì€ 'ì§ˆë¬¸ ì¬ì‘ì„±ê¸°'ì…ë‹ˆë‹¤.
        1. ì´ì „ ëŒ€í™” ë§¥ë½ì„ ì°¸ê³ í•˜ì—¬, ì‚¬ìš©ìì˜ ëª¨í˜¸í•œ ìµœì‹  ì§ˆë¬¸ì„ 'ë…ë¦½ì ì¸ ì§ˆë¬¸'ìœ¼ë¡œ ë‹¤ì‹œ ì‘ì„±í•˜ì„¸ìš”.
        2. ì ˆëŒ€ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•˜ì§€ ë§ˆì„¸ìš”. 
        3. ë‹¹ì‹ ì˜ ë‚´ë¶€ ì§€ì‹ì„ í™œìš©í•´ ì¸ë¬¼ì„ ì„¤ëª…í•˜ì§€ ë§ˆì„¸ìš”. (ì˜ˆ: 'ë°°ìš° ì†í˜¸ì§„' (X) -> 'ì†í˜¸ì§„ ìˆ˜ê°•ìƒ' (O))
        4. ë°˜ë“œì‹œ 'ë¬¸ì¥'ì´ ì•„ë‹Œ 'ì§ˆë¬¸(~ì¸ê°€ìš”?, ~ì…ë‹ˆê¹Œ?)' í˜•íƒœë¡œë§Œ ì¶œë ¥í•˜ì„¸ìš”.
    """

    # ì§ˆë¬¸ ì¬ì‘ì„± ê°€ì´ë“œ
    # "ì§ˆë¬¸ ì¬ì‘ì„±ì„ ìœ„í•œ êµ¬ì„±íŒì€ ì´ë ‡ê²Œ ìƒê²¼ì–´."
    # system, human, ai ë“±ì˜ ì—­í• ì„ ëª…í™•íˆ êµ¬ë¶„í•¨ìœ¼ë¡œì¨ ì§€ì‹œì‚¬í•­ì„ ë” ì˜ë”°ë¦„
    # systemì€ ë¼ˆëŒ€ë¥¼ ì˜ ì¡ì•„ì¤Œ
    rephrase_prompt = ChatPromptTemplate.from_messages([
        ("system", rephrase_system_prompt),
        MessagesPlaceholder("chat_history"),
        ("human", "{input}"),
    ])
    question_rewriter = rephrase_prompt | llm | StrOutputParser()

    def retrieve_documents(input_dict):
        query = question_rewriter.invoke(input_dict) if input_dict.get("chat_history") else input_dict["input"]
        return upgraded_retriever.invoke(query)

    # ìµœì¢… ë‹µë³€ ë°©ì‹ ì§€ì¹¨ì— ê´€í•œ í”„ë¡¬í”„íŠ¸
    qa_system_prompt = """
    ë‹¹ì‹ ì€ 'ëª¨ë‘ì˜ì—°êµ¬ì†Œ(ëª¨ë‘ì—°)' ìˆ˜ê°•ìƒë“¤ì˜ ë¹„ì„œì…ë‹ˆë‹¤.

    í˜„ì¬ ì‹œê°„ì€ {today} (KST)ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ 'ì–´ì œ, ë‚´ì¼' ë“±ì˜ í‘œí˜„ì€ {today}ë¥¼ ê¸°ì¤€ìœ¼ë¡œ íŒŒì•…í•˜ì„¸ìš”.
    ì˜¤ëŠ˜ì˜ ë‚ ì§œ/ìš”ì¼ì€ {today_ko} / {weekday_ko} ì…ë‹ˆë‹¤. ë‚ ì§œ ë° ìš”ì¼ ê´€ë ¨ ì§ˆë¬¸ì—ëŠ” ì¶”ë¡ í•˜ì§€ ë§ê³  ë°˜ë“œì‹œ ì´ ê°’ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ì„¸ìš”.

    ì œê³µëœ ë¬¸ì„œ ë‚´ìš©ë§Œì„ ê·¼ê±°ë¡œ ë‹µí•˜ì„¸ìš”. ê·¼ê±°ê°€ ì—†ìœ¼ë©´ 'ì •ë³´ê°€ ëª…í™•í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ìš´ì˜ë§¤ë‹ˆì €ë‹˜ì´ë‚˜ í¼ì‹¤ë‹˜ê»˜ ë¬¸ì˜í•´ì£¼ì„¸ìš”.'ë¼ê³ ë§Œ ëŒ€ë‹µí•˜ì„¸ìš”.
    ì‚¬ìš©ì ì…ë ¥ì— í¬í•¨ëœ ì‚¬ì‹¤ì€ ê·¼ê±°ë¡œ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.

    í›ˆë ¨ì¥ë ¤ê¸ˆì˜ ê²½ìš° ì£¼ì–´ì§„ ë‹¨ìœ„ ê¸°ê°„ ì¼ìˆ˜ì˜ 80%ì´ìƒì„ ì¶œì„í•´ì•¼ë§Œ ê¸ˆì•¡ì´ ì§€ê¸‰ë¨ì„ ëª…ì‹¬í•˜ì„¸ìš”. 
    ìµœëŒ€ 3ë¬¸ì¥ìœ¼ë¡œ ì§§ê²Œ ë‹µë³€í•˜ì„¸ìš”.

    {context}
    """
    
    # ë‹µë³€ ì‘ì„± ê°€ì´ë“œ
    # LLMì—ê²Œ ë„˜ê²¨ì¤„ í”„ë¡¬í”„íŠ¸ëŠ” ë‹µë³€ ë°©ì‹ ì§€ì¹¨ê³¼ ì´ì „ ëŒ€í™” ë¬¸ë§¥, ìƒˆë¡œ ë“¤ì–´ì˜¨ ì§ˆë¬¸ì„ ëª¨ë‘ ê²°í•©í•œ ì¦ê°•ëœ í”„ë¡¬í”„íŠ¸
    qa_prompt = ChatPromptTemplate.from_messages([
        ("system", qa_system_prompt),
        MessagesPlaceholder("chat_history"),
        ("human", "{input}"),
    ])
    
    qa_chain = (qa_prompt | llm | StrOutputParser())
    rag_core_chain = RunnablePassthrough.assign(context=retrieve_documents) | qa_chain

    # ëŒ€í™” ê¸°ë¡ ê´€ë¦¬ ê²°í•©
     # ë‹¨ê¸° ê¸°ì–µ ìƒì‹¤ì¦ì´ ìˆëŠ” AIì—ê²Œ ê¸°ì–µë ¥ì„ ë‹¬ì•„ì£¼ëŠ” ë‹¨ê³„ë¡œ, SESSION_IDë¥¼ í†µí•´ ì•„ ì´ ì‚¬ëŒì´ ì•„ê¹Œ ~ì§ˆë¬¸ì„ ë¬¼ì–´ë³¸ ê·¸ ì‚¬ëŒì´êµ¬ë‚˜ë¼ê³  ê¸°ì–µí•˜ê²Œ ë§Œë“¦
    return RunnableWithMessageHistory(
        rag_core_chain,
        lambda session_id: st.session_state.lc_store.setdefault(session_id, ChatMessageHistory()),
        input_messages_key="input",
        history_messages_key="chat_history"
    )


### [5] lottie animation ë¶ˆëŸ¬ì˜¤ê¸°
# lottie animation urlì„ ì…ë ¥ë°›ì•„ json ë¶ˆëŸ¬ì˜¤ëŠ” í•¨ìˆ˜
def load_lottie_url(url):
    r = requests.get(url)
    if r.status_code != 200:
        return None
    else:
        return r.json()

### [6] streamlitì„ í†µí•´ ë°°í¬í•œ ì›¹ì‚¬ì´íŠ¸ì—ì„œì˜ ë™ì‘
def run_app():
    # ë°ì´í„° ë° ì²´ì¸ ì¤€ë¹„
    rag_chain = get_conversational_rag_chain()

    # ì„¸ì…˜ ì´ˆê¸°í™”
    if "session_id" not in st.session_state:
        st.session_state["session_id"] = "default"
    if "messages" not in st.session_state:
        st.session_state["messages"] = [{"role": "assistant", "content": "ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”!"}]
    if "lc_store" not in st.session_state:
        st.session_state["lc_store"] = {}
    if "selected_date" not in st.session_state:
        st.session_state["selected_date"] = dt.date.today()

    with st.sidebar:
        st.title("ğŸ€ëª¨ë‘ì˜ ì—°êµ¬ì†Œ")
        st.markdown("---")
        
        # keyë¥¼ ê³ ì •í•˜ê³ , valueë¥¼ session_stateì—ì„œ ê°€ì ¸ì˜¤ë„ë¡ ê°•ì œí•˜ì—¬ streamlitì´ ì¬ì‹¤í–‰ë˜ì–´ë„ ì´ ìœ„ì ¯ì„ ìƒˆë¡œìš´ ê²ƒìœ¼ë¡œ ì°©ê°í•˜ì§€ ì•ŠìŒ.
        selected_date = st.date_input(
            "ì›í•˜ëŠ” ë‚ ì§œë¥¼ ì„ íƒí•˜ì„¸ìš”:",
            value=st.session_state.selected_date,
            key="unique_sidebar_date_final"
        )
        
        # ì„ íƒëœ ê°’ì„ ì„¸ì…˜ì— ì €ì¥
        st.session_state.selected_date = selected_date
        st.markdown("---")
        st.info(f"ì˜¤ëŠ˜ì€: **{selected_date}** ì…ë‹ˆë‹¤.")

        # í•™ìŠµ ê´€ë ¨ ì‚¬ì´íŠ¸
        st.markdown("---")
        st.header("ğŸ”—ê´€ë ¨ ì‚¬ì´íŠ¸")
        st.link_button("ëª¨ë‘ì˜ ì—°êµ¬ì†Œ í™ˆí˜ì´ì§€", "https://modulabs.co.kr")
        st.link_button("ë°ì‹¸ 5ê¸° ë…¸ì…˜ ì›Œí¬ìŠ¤í˜ì´ìŠ¤", "https://www.notion.so/New-5-25-07-07-26-01-08-New-23f2d25db62480828becc399aaa41877")
        st.link_button("ë°ì‹¸ 5ê¸° ZEP", "https://zep.us/play/8l5Vdo")
        st.link_button("LMS í™ˆí˜ì´ì§€", "https://lms.aiffel.io/")

        # ì²¨ë¶€íŒŒì¼
        st.markdown("---")
        st.header("ğŸ“„ì²¨ë¶€íŒŒì¼")
        try:
            with open(r"..\data\word\íœ´ê°€ì‹ ì²­ì„œ(ë°ì‹¸_5ê¸°).docx", 'rb') as file:
                st.download_button(
                    label='íœ´ê°€ì‹ ì²­ì„œ ë‹¤ìš´ë¡œë“œ',
                    data=file,
                    file_name='íœ´ê°€ì‹ ì²­ì„œ.docx',
                    mime='application/vnd.openxmlformats-officedocument.wordprocessingml.document'
                )
        except FileNotFoundError:
            st.warning(r"ì²¨ë¶€íŒŒì¼ ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”: ..\data\word\íœ´ê°€ì‹ ì²­ì„œ(ë°ì‹¸_5ê¸°).docx")

    # lottie animation ì¶”ê°€
    lottie_url = "https://assets2.lottiefiles.com/packages/lf20_1pxqjqps.json"
    lottie_animation = load_lottie_url(lottie_url)
    if lottie_animation:
        st_lottie(lottie_animation, speed=1, reverse=False, loop=True, quality="high", height=500, width=800, key="animation")

    # ì•ˆë‚´ ë¬¸êµ¬ ì¶”ê°€
    st.markdown(
        """
    <div style="text-align: center;">
        <p style="font-size:25px;">
            ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” ëª¨ë‘ë´‡ì…ë‹ˆë‹¤.<br>ì¦ê±°ìš´ ëª¨ë‘ì—° ìƒí™œì„ ìœ„í•œ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.ğŸ˜Š
        </p>
    </div>
    """,
        unsafe_allow_html=True
    )

    # ëŒ€í™” ë‚´ìš© ì¶œë ¥
    for msg in st.session_state["messages"]:
        st.chat_message(msg["role"]).write(msg["content"])

    # chat loop
    # ë³€ìˆ˜ì— ê°’ í• ë‹¹ê³¼ ë™ì‹œì— í• ë‹¹ëœ ê°’ì„ ë°˜í™˜í•˜ëŠ” (:=) ì—°ì‚°ì ì‚¬ìš©í•˜ì—¬ ê°€ë…ì„± í™•ë³´
    if question := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš” :)"):
        st.session_state["messages"].append({"role": "user", "content": question})
        st.chat_message("user").write(question)

        with st.chat_message("assistant"):
            with st.spinner("ìƒê° ì¤‘..."):
                # ë‚ ì§œ ì •ë³´ ìƒì„±
                date_info = {
                    "input": question,
                    "today": f"{st.session_state.selected_date} 00:00:00", # ì‚¬ì´ë“œë°”ì—ì„œ ê³ ë¥¸ ë‚ ì§œë¥¼ todayë¡œ ë™ì  ì£¼ì… (KST 00:00:00ë¡œ ê³ ì •)
                    "today_ko": st.session_state.selected_date.strftime("%Yë…„ %mì›” %dì¼"),
                    "weekday_ko": ["ì›”","í™”","ìˆ˜","ëª©","ê¸ˆ","í† ","ì¼"][st.session_state.selected_date.weekday()] + "ìš”ì¼"
                }
                
                # stream ê¸°ëŠ¥ì„ ì‚¬ìš©í•´ í•œê¸€ìì”© ì¶œë ¥í•˜ì—¬ ì‚¬ëŒì´ ì½ëŠ” ê²ƒì²˜ëŸ¼ ìì—°ìŠ¤ëŸ½ê²Œ ì¶œë ¥
                stream_gen = rag_chain.stream(date_info, config={"configurable": {"session_id": st.session_state["session_id"]}})
                full_response = st.write_stream(stream_gen)
                st.session_state.messages.append({"role": "assistant", "content": full_response})

# ì‹¤í–‰ ë³´í˜¸ êµ¬ë¬¸
if __name__ == "__main__":
    run_app()